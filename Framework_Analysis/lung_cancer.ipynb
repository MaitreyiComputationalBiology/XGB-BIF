{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dif7vbOS1Yux"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, cohen_kappa_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"Lung_gene_expression.csv\", index_col=\"Unnamed: 0\")\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "df[\"classes\"] = le.fit_transform(df[\"classes\"])  # Convert categorical labels to 0 and 1\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=[\"classes\"])\n",
        "y = df[\"classes\"]\n",
        "\n",
        "# Split dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Y-m_sc1gLT",
        "outputId": "3cd2f4a6-755b-4a9c-9ab5-cc707a88488c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['TSPAN6', 'TNMD', 'DPM1', 'SCYL3', 'FIRRM', 'FGR', 'CFH', 'FUCA2',\n",
            "       'GCLC', 'NFYA',\n",
            "       ...\n",
            "       'SNORA74C-2', 'ELOA3BP', 'NPBWR1', 'ELOA3DP', 'PDCD6-AHRR', 'LNCDAT',\n",
            "       'LOC124902537', 'RNF228', 'PANO1', 'classes'],\n",
            "      dtype='object', length=31506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,1:]"
      ],
      "metadata": {
        "id": "atF4GzUVt42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZgwF-bJt9_4",
        "outputId": "524ff870-db05-4540-bfb4-cd688dc224ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  TNMD       DPM1      SCYL3      FIRRM  \\\n",
              "TCGA-60-2712-01A-01R-0851-07  0.000000  10.835261   9.623881   9.335390   \n",
              "TCGA-56-7221-01A-11R-2045-07  3.321928  11.707790   9.743151  10.067434   \n",
              "TCGA-21-A5DI-01A-31R-A26W-07  0.000000  11.122828   8.174926   8.049849   \n",
              "TCGA-43-7657-11A-01R-2125-07  0.000000  10.760720   9.636625   7.693487   \n",
              "TCGA-43-7657-01A-31R-2125-07  0.000000  11.307201   8.957102   8.764872   \n",
              "...                                ...        ...        ...        ...   \n",
              "TCGA-39-5028-01A-01R-1443-07  1.584963  11.633903   9.194757   8.294621   \n",
              "TCGA-NC-A5HE-01A-11R-A26W-07  1.584963  11.428884  10.029287   9.897845   \n",
              "TCGA-66-2783-01A-01R-1201-07  0.000000  10.348728   9.262095   9.189825   \n",
              "TCGA-66-2795-01A-02R-0980-07  0.000000  11.051209   9.601771   9.731319   \n",
              "TCGA-66-2788-01A-01R-0980-07  0.000000  11.285980   9.611025   9.266787   \n",
              "\n",
              "                                    FGR        CFH      FUCA2       GCLC  \\\n",
              "TCGA-60-2712-01A-01R-0851-07  10.839204  12.055282  10.528454  12.670656   \n",
              "TCGA-56-7221-01A-11R-2045-07   9.082149  11.060696  11.078818  15.292573   \n",
              "TCGA-21-A5DI-01A-31R-A26W-07   7.339850  11.634357   9.807355  12.055282   \n",
              "TCGA-43-7657-11A-01R-2125-07  11.921097  13.641262  11.542065  10.691744   \n",
              "TCGA-43-7657-01A-31R-2125-07   8.751544  10.285402  11.861087  13.788311   \n",
              "...                                 ...        ...        ...        ...   \n",
              "TCGA-39-5028-01A-01R-1443-07   9.419960  13.058499  11.092757  11.814182   \n",
              "TCGA-NC-A5HE-01A-11R-A26W-07  11.770251  11.486835  11.574594  13.891689   \n",
              "TCGA-66-2783-01A-01R-1201-07   9.033423  10.631177  10.101976  12.842743   \n",
              "TCGA-66-2795-01A-02R-0980-07   9.019591  11.106563  10.083479  14.560751   \n",
              "TCGA-66-2788-01A-01R-0980-07  10.517669  13.743888  10.869594  12.897845   \n",
              "\n",
              "                                   NFYA      STPG1  ...  SNORA74C-2  ELOA3BP  \\\n",
              "TCGA-60-2712-01A-01R-0851-07  10.584963   8.861087  ...         0.0      0.0   \n",
              "TCGA-56-7221-01A-11R-2045-07  11.278449  10.490851  ...         0.0      0.0   \n",
              "TCGA-21-A5DI-01A-31R-A26W-07  10.453271   9.577429  ...         0.0      0.0   \n",
              "TCGA-43-7657-11A-01R-2125-07  10.557464  10.151017  ...         0.0      0.0   \n",
              "TCGA-43-7657-01A-31R-2125-07  10.868823  10.598983  ...         0.0      0.0   \n",
              "...                                 ...        ...  ...         ...      ...   \n",
              "TCGA-39-5028-01A-01R-1443-07  10.359750  10.213104  ...         0.0      0.0   \n",
              "TCGA-NC-A5HE-01A-11R-A26W-07  11.237807   8.159871  ...         0.0      0.0   \n",
              "TCGA-66-2783-01A-01R-1201-07  10.290019  10.030667  ...         0.0      0.0   \n",
              "TCGA-66-2795-01A-02R-0980-07  10.695228   8.375039  ...         0.0      0.0   \n",
              "TCGA-66-2788-01A-01R-0980-07  10.897089  10.200899  ...         0.0      0.0   \n",
              "\n",
              "                                 NPBWR1  ELOA3DP  PDCD6-AHRR    LNCDAT  \\\n",
              "TCGA-60-2712-01A-01R-0851-07   3.169925      0.0         0.0  0.000000   \n",
              "TCGA-56-7221-01A-11R-2045-07   9.167418      0.0         0.0  0.000000   \n",
              "TCGA-21-A5DI-01A-31R-A26W-07   7.851749      0.0         1.0  0.000000   \n",
              "TCGA-43-7657-11A-01R-2125-07   3.459432      0.0         0.0  0.000000   \n",
              "TCGA-43-7657-01A-31R-2125-07  13.429014      0.0         0.0  2.584963   \n",
              "...                                 ...      ...         ...       ...   \n",
              "TCGA-39-5028-01A-01R-1443-07   4.087463      0.0         0.0  1.000000   \n",
              "TCGA-NC-A5HE-01A-11R-A26W-07   6.339850      0.0         1.0  3.000000   \n",
              "TCGA-66-2783-01A-01R-1201-07   6.768184      0.0         0.0  0.000000   \n",
              "TCGA-66-2795-01A-02R-0980-07   7.139551      0.0         0.0  1.584963   \n",
              "TCGA-66-2788-01A-01R-0980-07   5.882643      0.0         0.0  0.000000   \n",
              "\n",
              "                              LOC124902537    RNF228     PANO1  classes  \n",
              "TCGA-60-2712-01A-01R-0851-07      0.000000  6.339850  4.643856        0  \n",
              "TCGA-56-7221-01A-11R-2045-07      0.000000  8.717676  4.700440        0  \n",
              "TCGA-21-A5DI-01A-31R-A26W-07      0.000000  6.686501  3.459432        0  \n",
              "TCGA-43-7657-11A-01R-2125-07      3.321928  4.392317  3.321928        1  \n",
              "TCGA-43-7657-01A-31R-2125-07      0.000000  6.954196  4.087463        0  \n",
              "...                                    ...       ...       ...      ...  \n",
              "TCGA-39-5028-01A-01R-1443-07      0.000000  4.000000  5.129283        0  \n",
              "TCGA-NC-A5HE-01A-11R-A26W-07      0.000000  5.584963  5.357552        0  \n",
              "TCGA-66-2783-01A-01R-1201-07      0.000000  6.475733  4.000000        0  \n",
              "TCGA-66-2795-01A-02R-0980-07      0.000000  5.807355  2.321928        0  \n",
              "TCGA-66-2788-01A-01R-0980-07      4.807355  6.554589  4.169925        0  \n",
              "\n",
              "[562 rows x 31505 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfd4835b-9c6f-4fdf-9e7a-81a0059d2563\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TNMD</th>\n",
              "      <th>DPM1</th>\n",
              "      <th>SCYL3</th>\n",
              "      <th>FIRRM</th>\n",
              "      <th>FGR</th>\n",
              "      <th>CFH</th>\n",
              "      <th>FUCA2</th>\n",
              "      <th>GCLC</th>\n",
              "      <th>NFYA</th>\n",
              "      <th>STPG1</th>\n",
              "      <th>...</th>\n",
              "      <th>SNORA74C-2</th>\n",
              "      <th>ELOA3BP</th>\n",
              "      <th>NPBWR1</th>\n",
              "      <th>ELOA3DP</th>\n",
              "      <th>PDCD6-AHRR</th>\n",
              "      <th>LNCDAT</th>\n",
              "      <th>LOC124902537</th>\n",
              "      <th>RNF228</th>\n",
              "      <th>PANO1</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-60-2712-01A-01R-0851-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.835261</td>\n",
              "      <td>9.623881</td>\n",
              "      <td>9.335390</td>\n",
              "      <td>10.839204</td>\n",
              "      <td>12.055282</td>\n",
              "      <td>10.528454</td>\n",
              "      <td>12.670656</td>\n",
              "      <td>10.584963</td>\n",
              "      <td>8.861087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.169925</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.339850</td>\n",
              "      <td>4.643856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-56-7221-01A-11R-2045-07</th>\n",
              "      <td>3.321928</td>\n",
              "      <td>11.707790</td>\n",
              "      <td>9.743151</td>\n",
              "      <td>10.067434</td>\n",
              "      <td>9.082149</td>\n",
              "      <td>11.060696</td>\n",
              "      <td>11.078818</td>\n",
              "      <td>15.292573</td>\n",
              "      <td>11.278449</td>\n",
              "      <td>10.490851</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.167418</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.717676</td>\n",
              "      <td>4.700440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-21-A5DI-01A-31R-A26W-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.122828</td>\n",
              "      <td>8.174926</td>\n",
              "      <td>8.049849</td>\n",
              "      <td>7.339850</td>\n",
              "      <td>11.634357</td>\n",
              "      <td>9.807355</td>\n",
              "      <td>12.055282</td>\n",
              "      <td>10.453271</td>\n",
              "      <td>9.577429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.851749</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.686501</td>\n",
              "      <td>3.459432</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-43-7657-11A-01R-2125-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.760720</td>\n",
              "      <td>9.636625</td>\n",
              "      <td>7.693487</td>\n",
              "      <td>11.921097</td>\n",
              "      <td>13.641262</td>\n",
              "      <td>11.542065</td>\n",
              "      <td>10.691744</td>\n",
              "      <td>10.557464</td>\n",
              "      <td>10.151017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.459432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.321928</td>\n",
              "      <td>4.392317</td>\n",
              "      <td>3.321928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-43-7657-01A-31R-2125-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.307201</td>\n",
              "      <td>8.957102</td>\n",
              "      <td>8.764872</td>\n",
              "      <td>8.751544</td>\n",
              "      <td>10.285402</td>\n",
              "      <td>11.861087</td>\n",
              "      <td>13.788311</td>\n",
              "      <td>10.868823</td>\n",
              "      <td>10.598983</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.429014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.954196</td>\n",
              "      <td>4.087463</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-39-5028-01A-01R-1443-07</th>\n",
              "      <td>1.584963</td>\n",
              "      <td>11.633903</td>\n",
              "      <td>9.194757</td>\n",
              "      <td>8.294621</td>\n",
              "      <td>9.419960</td>\n",
              "      <td>13.058499</td>\n",
              "      <td>11.092757</td>\n",
              "      <td>11.814182</td>\n",
              "      <td>10.359750</td>\n",
              "      <td>10.213104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.087463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.129283</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-NC-A5HE-01A-11R-A26W-07</th>\n",
              "      <td>1.584963</td>\n",
              "      <td>11.428884</td>\n",
              "      <td>10.029287</td>\n",
              "      <td>9.897845</td>\n",
              "      <td>11.770251</td>\n",
              "      <td>11.486835</td>\n",
              "      <td>11.574594</td>\n",
              "      <td>13.891689</td>\n",
              "      <td>11.237807</td>\n",
              "      <td>8.159871</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.339850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.584963</td>\n",
              "      <td>5.357552</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-66-2783-01A-01R-1201-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.348728</td>\n",
              "      <td>9.262095</td>\n",
              "      <td>9.189825</td>\n",
              "      <td>9.033423</td>\n",
              "      <td>10.631177</td>\n",
              "      <td>10.101976</td>\n",
              "      <td>12.842743</td>\n",
              "      <td>10.290019</td>\n",
              "      <td>10.030667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.768184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.475733</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-66-2795-01A-02R-0980-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.051209</td>\n",
              "      <td>9.601771</td>\n",
              "      <td>9.731319</td>\n",
              "      <td>9.019591</td>\n",
              "      <td>11.106563</td>\n",
              "      <td>10.083479</td>\n",
              "      <td>14.560751</td>\n",
              "      <td>10.695228</td>\n",
              "      <td>8.375039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.139551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.807355</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-66-2788-01A-01R-0980-07</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.285980</td>\n",
              "      <td>9.611025</td>\n",
              "      <td>9.266787</td>\n",
              "      <td>10.517669</td>\n",
              "      <td>13.743888</td>\n",
              "      <td>10.869594</td>\n",
              "      <td>12.897845</td>\n",
              "      <td>10.897089</td>\n",
              "      <td>10.200899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.882643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.807355</td>\n",
              "      <td>6.554589</td>\n",
              "      <td>4.169925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>562 rows × 31505 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfd4835b-9c6f-4fdf-9e7a-81a0059d2563')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfd4835b-9c6f-4fdf-9e7a-81a0059d2563 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfd4835b-9c6f-4fdf-9e7a-81a0059d2563');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4168e68-4040-40ff-9c53-81723a3405e6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4168e68-4040-40ff-9c53-81723a3405e6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4168e68-4040-40ff-9c53-81723a3405e6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Get feature importances\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create a DataFrame for importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Gene': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Select Top 1000 Genes\n",
        "# ---------------------------\n",
        "top_genes_df = importance_df.sort_values(by='Importance', ascending=False).head(1000)\n",
        "\n",
        "# Optional: Save to CSV\n",
        "top_genes_df.to_csv('top_1000_genes.csv', index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# DONE!\n",
        "# ---------------------------\n",
        "print(\"Top 1000 genes saved to 'top_1000_genes.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hHn36V7FYjh",
        "outputId": "c47ddc55-d116-4da9-88c2-9f0b986a39a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:31:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1000 genes saved to 'top_1000_genes.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#None + RF\n",
        "# Initialize and train the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "y_pred_proba = rf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgl-R2HM1xcz",
        "outputId": "9f3e6a78-f787-44b8-d0a3-8ac539608990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9952\n",
            "Kappa: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#None + XGB\n",
        "# Initialize and train the XGBoost classifier\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric=\"logloss\")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "y_pred_proba = xgb_clf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q80bdqV10pF",
        "outputId": "09cb1fa4-c8e5-4732-cc85-991d9320212a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9763\n",
            "Precision: 0.9231\n",
            "AUC: 0.9955\n",
            "Kappa: 0.8443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#None + LR\n",
        "# Initialize and train the Logistic Regression model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr.predict(X_test)\n",
        "y_pred_proba = lr.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "scores = cross_val_score(lr, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(np.unique(y_pred, return_counts=True))\n",
        "\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"cvs:\",scores.mean())\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iEPF3uk13pC",
        "outputId": "545e6920-d686-4c0e-f0a6-03ae2329864f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([153,  16]))\n",
            "cvs: 0.9982142857142857\n",
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9970\n",
            "Kappa: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# None + SVM\n",
        "# Initialize and train the SVM model (with probability=True for AUC calculation)\n",
        "svm_clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "y_pred_proba = svm_clf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIVJ1TyE16rM",
        "outputId": "535ad5b3-f8e2-4b45-f4b9-835ff2e37b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9965\n",
            "Kappa: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF + SVM\n",
        "# Feature selection using Random Forest\n",
        "from sklearn.preprocessing import StandardScaler # Import StandardScaler\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features (important for SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train the SVM model\n",
        "    svm_clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "    svm_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = svm_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nResults for Top {num_features} Features:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    print(f\"Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-fzb1J_1-Qp",
        "outputId": "6ddbb63a-9b1a-4234-eab8-b0dfeef38b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Top 10 Features:\n",
            "Accuracy: 0.9882\n",
            "Precision: 0.9333\n",
            "AUC: 0.9944\n",
            "Kappa: 0.9268\n",
            "\n",
            "Results for Top 50 Features:\n",
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9939\n",
            "Kappa: 0.9645\n",
            "\n",
            "Results for Top 100 Features:\n",
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9944\n",
            "Kappa: 0.9645\n",
            "\n",
            "Results for Top 500 Features:\n",
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9948\n",
            "Kappa: 0.9645\n",
            "\n",
            "Results for Top 1000 Features:\n",
            "Accuracy: 0.9941\n",
            "Precision: 0.9375\n",
            "AUC: 0.9957\n",
            "Kappa: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF + LR\n",
        "# Feature selection using Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train Logistic Regression model with best settings\n",
        "    lr_clf = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=500, random_state=42)\n",
        "    lr_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = lr_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = lr_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkR4jdrR2Bfu",
        "outputId": "19776f04-8a68-4696-daca-340e10d653ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-21cdacf3c988>:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Features       AUC  Accuracy  Precision     Kappa\n",
            "0       10  0.996104  0.982249   0.875000  0.893465\n",
            "1       50  0.994372  0.988166   0.882353  0.930992\n",
            "2      100  0.996537  0.988166   0.882353  0.930992\n",
            "3      500  0.996537  0.988166   0.882353  0.930992\n",
            "4     1000  0.996104  0.982249   0.833333  0.899345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF + RF\n",
        "# Feature selection using Random Forest\n",
        "rf_selector = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, random_state=42, n_jobs=-1)\n",
        "rf_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(rf_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Train Random Forest model with optimized settings\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=500,  # More trees for better performance\n",
        "        max_depth=None,    # Fully grown trees for optimal learning\n",
        "        min_samples_split=2,  # Ensures small splits, capturing more information\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_clf.predict(X_test_selected)\n",
        "    y_pred_proba = rf_clf.predict_proba(X_test_selected)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYeKm2sk2E5K",
        "outputId": "365cc496-c566-4d0b-8812-19f58c3fd1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-4188139004fd>:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Features       AUC  Accuracy  Precision    Kappa\n",
            "0       10  0.994372  0.988166   0.933333  0.92684\n",
            "1       50  0.994156  0.988166   0.933333  0.92684\n",
            "2      100  0.993723  0.988166   0.933333  0.92684\n",
            "3      500  0.994156  0.988166   0.933333  0.92684\n",
            "4     1000  0.994589  0.988166   0.933333  0.92684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF + XGB\n",
        "# Feature selection using Random Forest\n",
        "\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "\n",
        "rf_selector = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42, n_jobs=-1)\n",
        "rf_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(rf_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train XGBoost model with best settings\n",
        "    xgb_clf = XGBClassifier(\n",
        "        n_estimators=500,  # More trees for better learning\n",
        "        learning_rate=0.05,  # Slower learning for better generalization\n",
        "        max_depth=6,  # Optimal depth to prevent overfitting\n",
        "        subsample=0.8,  # Helps prevent overfitting\n",
        "        colsample_bytree=0.8,  # Randomly selects features for better generalization\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\"\n",
        "    )\n",
        "    xgb_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = xgb_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = xgb_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ULtGT-p52H9D",
        "outputId": "a1f6b14c-6a53-47e2-8e24-3c1ff3e9b7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'StandardScaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0e17c69f3ec8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Standardize the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB + SVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features (important for SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train SVM classifier\n",
        "    svm_clf = SVC(kernel=\"rbf\", C=1.0, probability=True, random_state=42)\n",
        "    svm_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = svm_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC5j5z3I2I8s",
        "outputId": "400e3807-3f85-4e18-db6b-d7a6296d1e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:45:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "<ipython-input-13-1ff734075625>:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Features       AUC  Accuracy  Precision     Kappa\n",
            "0       10  0.994372  0.994083     0.9375  0.964488\n",
            "1       50  0.994372  0.994083     0.9375  0.964488\n",
            "2      100  0.996104  0.994083     0.9375  0.964488\n",
            "3      500  0.996104  0.994083     0.9375  0.964488\n",
            "4     1000  0.995671  0.994083     0.9375  0.964488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB + LR\n",
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features (important for Logistic Regression)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train Logistic Regression classifier\n",
        "    lr_clf = LogisticRegression(solver=\"liblinear\", C=1.0, random_state=42)\n",
        "    lr_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = lr_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = lr_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "qYhxYZn_2Nhl",
        "outputId": "8818b9ec-5adb-4ea5-e45d-d2720b4580db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:43:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'StandardScaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-804c789101dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Standardize the features (important for Logistic Regression)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB + RF\n",
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Train Random Forest classifier\n",
        "    rf_clf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2,\n",
        "                                    random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_clf.predict(X_test_selected)\n",
        "    y_pred_proba = rf_clf.predict_proba(X_test_selected)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "2Vv_lQ1Z2R6h",
        "outputId": "279cf29c-94f5-41ed-a78e-091c362e142f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'XGBClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f8dc8f20b011>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#XGB + RF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Train XGBoost to get feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n\u001b[0m\u001b[1;32m      4\u001b[0m                              \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              use_label_encoder=False, eval_metric=\"logloss\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variance threshold + XGB\n",
        "# Define variance thresholds to experiment with\n",
        "variance_thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different variance thresholds\n",
        "for threshold in variance_thresholds:\n",
        "    # Apply VarianceThreshold feature selection\n",
        "    selector = VarianceThreshold(threshold=threshold)\n",
        "    X_train_selected = selector.fit_transform(X_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Get selected feature names\n",
        "    selected_features = X.columns[selector.get_support()]\n",
        "    num_features = len(selected_features)\n",
        "\n",
        "    # Train XGBoost classifier\n",
        "    xgb_clf = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\"\n",
        "    )\n",
        "    xgb_clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = xgb_clf.predict(X_test_selected)\n",
        "    y_pred_proba = xgb_clf.predict_proba(X_test_selected)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "HYEeoBUl2VTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698f2d50-0378-47ee-b9f3-7f7314cd186f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:06:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "<ipython-input-44-480001a55502>:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:07:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:09:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:10:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:11:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variance Threshold Num Features       AUC  Accuracy  Precision     Kappa\n",
            "0               0.001        31504  0.994372  0.982249   0.928571  0.886856\n",
            "1               0.005        31502  0.991991  0.976331   0.923077  0.844311\n",
            "2               0.010        31498  0.993074  0.982249   0.928571  0.886856\n",
            "3               0.050        31237  0.993290  0.976331   0.923077  0.844311\n",
            "4               0.100        30372  0.993290  0.982249   0.928571  0.886856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variance Threshold + SVM\n",
        "# Define variance thresholds to experiment with\n",
        "variance_thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different variance thresholds\n",
        "for threshold in variance_thresholds:\n",
        "    # Apply VarianceThreshold feature selection\n",
        "    selector = VarianceThreshold(threshold=threshold)\n",
        "    X_train_selected = selector.fit_transform(X_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Get selected feature names\n",
        "    selected_features = X.columns[selector.get_support()]\n",
        "    num_features = len(selected_features)\n",
        "\n",
        "    # Standardize the features (SVM is sensitive to scaling)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train SVM classifier\n",
        "    svm_clf = SVC(kernel=\"rbf\", probability=True, C=1, gamma=\"scale\", random_state=42)\n",
        "    svm_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = svm_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "ElQU5DAm3mP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1c5e6b-c1b6-4ae3-99bd-abe251bb9e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-4c8ce2bce1cc>:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variance Threshold Num Features       AUC  Accuracy  Precision     Kappa\n",
            "0               0.001        31504  0.995238  0.994083     0.9375  0.964488\n",
            "1               0.005        31502  0.995238  0.994083     0.9375  0.964488\n",
            "2               0.010        31498  0.995238  0.994083     0.9375  0.964488\n",
            "3               0.050        31237  0.995238  0.994083     0.9375  0.964488\n",
            "4               0.100        30372  0.995238  0.994083     0.9375  0.964488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variance threshold + LR\n",
        "\n",
        "# Define variance thresholds to test\n",
        "variance_thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different variance thresholds\n",
        "for threshold in variance_thresholds:\n",
        "    # Apply VarianceThreshold feature selection\n",
        "    selector = VarianceThreshold(threshold=threshold)\n",
        "    X_train_selected = selector.fit_transform(X_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Get the number of selected features\n",
        "    num_features = X_train_selected.shape[1]\n",
        "\n",
        "    # Standardize the features (LR benefits from scaling)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    lr_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
        "    lr_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = lr_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = lr_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "UuVIkOqR3nYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05be7664-7277-417a-aa8f-2e6da8988b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-fc1b02ff988e>:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variance Threshold Num Features       AUC  Accuracy  Precision     Kappa\n",
            "0               0.001        31504  0.996537  0.934911   0.576923  0.697674\n",
            "1               0.005        31502  0.996537  0.934911   0.576923  0.697674\n",
            "2               0.010        31498  0.996537  0.934911   0.576923  0.697674\n",
            "3               0.050        31237  0.996537  0.934911   0.576923  0.697674\n",
            "4               0.100        30372  0.996537  0.934911   0.576923  0.697674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variance treshold + RF\n",
        "# Define variance thresholds to test\n",
        "variance_thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different variance thresholds\n",
        "for threshold in variance_thresholds:\n",
        "    # Apply VarianceThreshold feature selection\n",
        "    selector = VarianceThreshold(threshold=threshold)\n",
        "    X_train_selected = selector.fit_transform(X_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    # Get the number of selected features\n",
        "    num_features = X_train_selected.shape[1]\n",
        "\n",
        "    # Train Random Forest classifier\n",
        "    rf_clf = RandomForestClassifier(\n",
        "        n_estimators=200,  # More trees for better learning\n",
        "        max_depth=None,  # Let it grow deep\n",
        "        min_samples_split=2,  # Standard split settings\n",
        "        n_jobs=-1,  # Use all processors\n",
        "        random_state=42\n",
        "    )\n",
        "    rf_clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_clf.predict(X_test_selected)\n",
        "    y_pred_proba = rf_clf.predict_proba(X_test_selected)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Variance Threshold\", \"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "mC56kbjk3tw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbe3912-792d-4fb4-dc88-81c387f90a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-5419cb2f25dc>:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([[threshold, num_features, auc, accuracy, precision, kappa]],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variance Threshold Num Features       AUC  Accuracy  Precision     Kappa\n",
            "0               0.001        31504  0.993506  0.994083   0.937500  0.964488\n",
            "1               0.005        31502  0.993939  0.994083   0.937500  0.964488\n",
            "2               0.010        31498  0.994372  0.988166   0.933333  0.926840\n",
            "3               0.050        31237  0.994805  0.994083   0.937500  0.964488\n",
            "4               0.100        30372  0.995238  0.994083   0.937500  0.964488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual info + XGB\n",
        "# Define feature selection sizes\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Compute Mutual Information scores\n",
        "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
        "mi_series = pd.Series(mi_scores, index=X_train.columns)\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = mi_series.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train XGBoost model with optimized settings\n",
        "    xgb_clf = XGBClassifier(\n",
        "        n_estimators=500,  # More trees for better learning\n",
        "        learning_rate=0.05,  # Slower learning for better generalization\n",
        "        max_depth=6,  # Optimal depth to prevent overfitting\n",
        "        subsample=0.8,  # Helps prevent overfitting\n",
        "        colsample_bytree=0.8,  # Randomly selects features for better generalization\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\"\n",
        "    )\n",
        "    xgb_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = xgb_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = xgb_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Num Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "v-OiWxcy3yCf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "06341172-7d17-46ac-f10f-e4232f9002fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mutual_info_classif' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-42cd4b9bcb6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute Mutual Information scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmi_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmi_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mutual_info_classif' is not defined"
          ]
        }
      ]
    }
  ]
}